{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6003c2-524d-40f1-a0ca-776f1f4fbf5a",
   "metadata": {},
   "source": [
    "# Hyperparameter tune VIT model on All Hurricanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b1ed0bc-d166-4f5d-a1fb-497e4bc65368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch import tensor\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torch.utils.data\n",
    "from torcheval.metrics.functional import multiclass_precision, multiclass_f1_score, multiclass_recall, multiclass_accuracy\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torchsummary import summary\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from numpy import where\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib\n",
    "\n",
    "from datetime import date\n",
    "# from skorch import NeuralNetClassifier\n",
    "# from skorch.helper import predefined_split\n",
    "# from skorch.callbacks import LRScheduler, Checkpoint, Freezer, EarlyStopping\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(360);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317d676-8123-4933-a7bc-e045cfaf1774",
   "metadata": {},
   "source": [
    "### Setup Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9180b-4b11-40b6-98d8-eb1b4b846cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current Path : \", os.getcwd())\n",
    "os.chdir('../..')\n",
    "print(\"Current Path : \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c687b6-04bf-47a9-a833-5ce4270f5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "print(\"Root Project Path : \", ROOT_DIR)\n",
    "ROOT_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'xview_building_damage')\n",
    "CSV_DIR = os.path.join(ROOT_DATA_DIR, 'csv')\n",
    "print(\"Data CSV Path : \", CSV_DIR)\n",
    "TRAIN_DIR=os.path.join(ROOT_DATA_DIR, 'train')\n",
    "print(\"Train Data Path : \", TRAIN_DIR)\n",
    "HOLD_DIR=os.path.join(ROOT_DATA_DIR, 'hold')\n",
    "print(\"Validation Data Path : \", HOLD_DIR)\n",
    "TEST_DIR=os.path.join(ROOT_DATA_DIR, 'test')\n",
    "print(\"Test Data Path : \", TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f059c57-9416-4b38-ab70-568ae354dc0e",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc5a31-6f89-492f-84eb-87450fec9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_stats(data_loader):\n",
    "    labels = [labels for i, (images, labels) in enumerate(data_loader)]\n",
    "    labels = torch.cat((labels), 0)\n",
    "    labels_count = labels.unique(return_counts=True)\n",
    "    \n",
    "    print('The number of samples per classes in training dataset:\\n')\n",
    "    for label, count in zip(labels_count[0], labels_count[1]):\n",
    "        print('\\t {}: {}'.format(label, count))\n",
    "    return labels, labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520e7a1-78c1-469e-ab81-89fe1b082449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2,p=0.5),\n",
    "    transforms.RandomAutocontrast(p=0.5),\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    transforms.Resize(size=(224, 224)),    \n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    transforms.Resize(size=(224, 224)),    \n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), \n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed740cc5-4ae1-4d10-90ad-8517576704e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set records :  64454\n",
      "Validation set records :  22107\n",
      "Test set records :  19299\n"
     ]
    }
   ],
   "source": [
    "train_all_dataset = datasets.ImageFolder(os.path.join(TRAIN_DIR, 'img_mask_ov_crop_class'), transform=train_transform)\n",
    "valid_all_dataset = datasets.ImageFolder(os.path.join( HOLD_DIR, 'img_mask_ov_crop_class'), transform=valid_transform)\n",
    "test_all_dataset = datasets.ImageFolder(os.path.join( TEST_DIR, 'img_mask_ov_crop_class'), transform=test_transform)\n",
    "\n",
    "\n",
    "print(\"Train set records : \", len(train_all_dataset))\n",
    "print(\"Validation set records : \", len(valid_all_dataset))\n",
    "print(\"Test set records : \", len(test_all_dataset))\n",
    "\n",
    "#trainset_all = torch.utils.data.Subset(train_all_dataset, list(range(len(train_all_dataset))))\n",
    "#testset_all = torch.utils.data.Subset(test_all_dataset, list(range(len(test_all_dataset))))\n",
    "#validset_all = torch.utils.data.Subset(valid_all_dataset, list(range(len(valid_all_dataset))))\n",
    "\n",
    "#sampler = torch.utils.data.sampler.WeightedRandomSampler(element_weights, num_epoch_elements, replacement=False)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader_all = DataLoader(trainset_all, batch_size=batch_size, num_workers=2)\n",
    "valid_loader_all = DataLoader(validset_all, batch_size=batch_size, num_workers=2)\n",
    "test_loader_all = DataLoader(testset_all, batch_size=batch_size, num_workers= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1c93c60-9ba9-42ef-8acb-b6ba8afbd352",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fileNames = test_all_dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893ca25-487f-4d5d-aecc-07c00bd620a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_all_dataset.classes\n",
    "print(\"class_names \",class_names)\n",
    "\n",
    "class_dict = train_all_dataset.class_to_idx\n",
    "print(\"class_dict \",class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8ac37-2b41-4c90-9670-2091c701385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"================================================\")\n",
    "print(f\"Train data:\\n{train_all_dataset}\")\n",
    "print(f\"Validation data:\\n{valid_all_dataset}\")\n",
    "print(f\"Test data:\\n{test_all_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e216a7-ccf9-4c4e-a089-f0601a2bfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_labels, train_all_labels_count = get_label_stats(train_loader_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b759b7f-70da-4ac6-bb9a-1f3354a797e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_all_labels, valid_all_labels_count = get_label_stats(valid_loader_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e7224-9b3e-4464-89b8-91a8da1fbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, test_labels_count = get_label_stats(test_loader_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c049b49-f0b0-45bd-9717-0dc93757a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(labels):\n",
    "    class_counts = np.bincount(labels)\n",
    "    num_classes = len(class_counts)\n",
    "    total_samples = len(labels)\n",
    "    \n",
    "    class_weights = []\n",
    "    for count in class_counts:\n",
    "        weight = 1 / (count / total_samples)\n",
    "        class_weights.append(weight)\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0d4d5-2446-4946-bade-f22c117ff749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all=get_class_weights(train_all_labels)\n",
    "print(\"Class weights\", class_weights_all)\n",
    "\n",
    "class_weights_all = torch.tensor(class_weights_all, dtype=torch.float32).to('cpu')\n",
    "# balanced sampler\n",
    "weights_all = class_weights_all[train_all_labels]\n",
    "ws_all = WeightedRandomSampler(weights_all, len(weights_all), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad03036-7de1-4a32-9f60-dcd9837d59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_ws_all = DataLoader(trainset_all, batch_size=batch_size, sampler=ws_all , num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93948824-4930-48b6-999c-8735c9794433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ws_all, train_labels_count_ws_all = get_label_stats(train_loader_ws_all)\n",
    "\n",
    "#train_labels_ws, train_labels_count_ws = get_label_stats(train_loader_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590f253-34e4-4b8a-b1f5-ccd1b8c90b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_loader_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a598bdd-1710-4dde-8d7b-7b45a9f7639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619f458-6da6-43e0-85ae-4b9fa3191854",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "225dd88b-cbb1-4fdd-843f-0036c282455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds_list, target_list, num_classes = 4 ):\n",
    "    pred_ts=tensor(preds_list)\n",
    "    target_ts = tensor(target_list)\n",
    "    \n",
    "    accuracy = multiclass_accuracy(pred_ts, target_ts, num_classes=4)\n",
    "    \n",
    "    f1_score = multiclass_f1_score(pred_ts, target_ts, num_classes=4, average=\"weighted\")\n",
    "    \n",
    "    precision = multiclass_precision(pred_ts, target_ts, num_classes=4, average=\"weighted\")\n",
    "    recall = multiclass_recall(pred_ts, target_ts, num_classes=4, average=\"weighted\")\n",
    "    \n",
    "    print(\"Accuracy :\", accuracy)\n",
    "    print(\"F1-score : \", f1_score)\n",
    "    print(\"Precision : \", precision)\n",
    "    print(\"Recall : \", recall)\n",
    "    return accuracy, f1_score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e526ebf-4b50-48e9-9528-5b290c48188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F1Score(preds_list, target_list, num_classes = 4):\n",
    "    pred_ts=tensor(preds_list)\n",
    "    target_ts = tensor(target_list)\n",
    "    return multiclass_f1_score(pred_ts, target_ts, num_classes=4, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdc0ed86-3e07-4ef3-886b-548a191c3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Accuracy(preds_list, target_list, num_classes = 4):\n",
    "    pred_ts=tensor(preds_list)\n",
    "    target_ts = tensor(target_list)\n",
    "    return multiclass_accuracy(pred_ts, target_ts, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "402b5e5e-30ec-4d40-a176-642cb53bdd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Precision(preds_list, target_list, num_classes = 4):\n",
    "    pred_ts=tensor(preds_list)\n",
    "    target_ts = tensor(target_list)\n",
    "    return multiclass_precision(pred_ts, target_ts, num_classes=4, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0b00533-3b10-44d0-acb2-1fad3d758c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Recall(preds_list, target_list, num_classes = 4):\n",
    "    pred_ts=tensor(preds_list)\n",
    "    target_ts = tensor(target_list)\n",
    "    return multiclass_recall(pred_ts, target_ts, num_classes=4, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efa430-61fa-4d3a-a59b-219e78d8e13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7287e2b8-6be3-4248-b186-00d4a9e82893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vit_base_patch16_224\"\n",
    "def setup_device():\n",
    "    device = 'cpu' \n",
    "    if torch.cuda.is_available(): \n",
    "     device='cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "     device = 'mps' \n",
    "    \n",
    "    print(\"device = \", device)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e55d8e42-59b1-4443-8230-93d4e41dc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_model():\n",
    "    vision_transformer = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "    print(\"=============================== Model heads ==========================\")\n",
    "    print(vision_transformer.heads)\n",
    "    # fine-tune with dataset\n",
    "\n",
    "    # change the number of output classes\n",
    "    vision_transformer.heads = nn.Linear(in_features=768, out_features=len(class_names), bias=True)\n",
    "    \n",
    "    # freeze the parameters except the last linear layer\n",
    "    #\n",
    "    # freeze weights\n",
    "    for p in vision_transformer.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    # unfreeze weights of classification head to train\n",
    "    for p in vision_transformer.heads.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    print(\"=============================== Model Layers ==========================\")\n",
    "    for layer_name, p in vision_transformer.named_parameters():\n",
    "        print('Layer Name: {}, Frozen: {}'.format(layer_name, not p.requires_grad))\n",
    "        print()\n",
    "\n",
    "    return vision_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b65cf5c0-4fbd-4294-9f82-0925ca9e7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_model_with_classes(number_of_classes=4):\n",
    "    vision_transformer = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "    # fine-tune with dataset\n",
    "    # change the number of output classes\n",
    "    vision_transformer.heads = nn.Linear(in_features=768, out_features=number_of_classes, bias=True)\n",
    "    \n",
    "    # freeze the parameters except the last linear layer\n",
    "    #\n",
    "    # freeze weights\n",
    "    for p in vision_transformer.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    # unfreeze weights of classification head to train\n",
    "    for p in vision_transformer.heads.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    return vision_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "85b19a58-2d08-400b-a9ef-6b8e0f567e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight_decay(batch, train_data_len, nepoches, lambda_norm):\n",
    "    return lambda_norm * math.sqrt((batch/(train_data_len * nepoches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7335086-8752-430e-b2c1-243abdada04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_focal_loss(ce_loss, alpha =0.3 ,gamma =2):\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = (alpha * (1-pt)**gamma * ce_loss).mean()\n",
    "    return focal_loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e78f46f-f882-4cb9-b3d4-c87d5c468ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss_list, valid_loss_list, n_epoch, title):\n",
    "    plt.title(\"Training and Validation \"+title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(title)\n",
    "    \n",
    "    # plot losses\n",
    "    x = list(range(1, n_epoch + 1))\n",
    "    plt.plot(x, train_loss_list, color =\"blue\", label='Train')\n",
    "    plt.plot(x, valid_loss_list, color=\"orange\", label='Validation')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xticks(x)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "616488a9-a19f-4885-aaf2-be709907a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(class_correct, class_total, class_names, accuracy ):\n",
    "    n_class = len(class_names)\n",
    "\n",
    "    class_accuracy = class_correct / class_total\n",
    "\n",
    "    print('Test Accuracy of Classes')\n",
    "    print()\n",
    "    \n",
    "    for c in range(n_class):\n",
    "        print('{}\\t: {}% \\t ({}/{})'.format(class_names[c],\n",
    "                                    int(class_accuracy[c] * 100), int(class_correct[c]), int(class_total[c])) )\n",
    "    \n",
    "    print()\n",
    "    print('Test Accuracy of Dataset: \\t {}% \\t ({}/{})'.format(int(accuracy),\n",
    "                                                               int(np.sum(class_correct)), int(np.sum(class_total)) ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e6d80bf8-ce3f-41a5-a66f-4fd013208ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vision_transformer = get_vit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da33603b-977b-4fa7-bff9-344760b42791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, fileName):\n",
    "    print(\"Started : Saving the trained Model\")\n",
    "    joblib.dump(model, filename)\n",
    "    print(\"Finished : Saving the trained Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8324dbb7-f662-49e5-98ba-49e9f230d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_list = []\n",
    "final_target_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94a501df-a7b5-43f2-a831-9bb8378a4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_eval_model(device, \n",
    "                     optimizer, \n",
    "                     criterion ,\n",
    "                     train_on_gpu, \n",
    "                     class_weights, \n",
    "                     valid_loader,\n",
    "                     test_loader, \n",
    "                     model=vision_transformer,  \n",
    "                     n_epoch = 15,\n",
    "                     data = train_loader_ws_all):\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # train_focal_loss_list, valid_focal_loss_list = [], []\n",
    "    \n",
    "    # move model to GPU\n",
    "    if train_on_gpu:\n",
    "        print(\"Device available : \", device)\n",
    "        model.to(device)\n",
    "    \n",
    "    # prepare model for training\n",
    "    model.train()\n",
    "    \n",
    "    for e in range(n_epoch):\n",
    "        #print(\"Start Iteration \", e)\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        # train_focal_loss = 0.0\n",
    "        # valid_focal_loss =0.0\n",
    "    \n",
    "        # get batch data\n",
    "        for i, (images, targets) in enumerate(data):\n",
    "            \n",
    "            # move to gpu if available\n",
    "            if train_on_gpu:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "    \n",
    "            # clear grad\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # feedforward data\n",
    "            outputs = model(images)\n",
    "    \n",
    "            # calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            #fl = get_focal_loss(loss)\n",
    "    \n",
    "            # backward pass, calculate gradients\n",
    "            loss.backward()\n",
    "            #fl.backward()\n",
    "    \n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "    \n",
    "            # track loss\n",
    "            train_loss += loss.item()\n",
    "            #train_focal_loss += fl.item()\n",
    "    \n",
    "        # set model to evaluation mode\n",
    "        model.eval()\n",
    "    \n",
    "        # validate model\n",
    "        for images, targets in valid_loader:\n",
    "    \n",
    "            # move to gpu if available\n",
    "            if train_on_gpu:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "    \n",
    "            # turn off gradients\n",
    "            with torch.no_grad():\n",
    "    \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                #fl = get_focal_loss(loss)\n",
    "                valid_loss += loss.item()\n",
    "                #valid_focal_loss += fl.item()\n",
    "    \n",
    "        # set model back to training mode\n",
    "        model.train()\n",
    "    \n",
    "        # get average loss values\n",
    "        train_loss = train_loss / len(data)\n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "        # train_focal_loss = train_focal_loss/len(data)\n",
    "        # valid_focal_loss = valid_focal_loss/len(valid_loader)\n",
    "    \n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        # train_focal_loss_list.append(train_focal_loss)\n",
    "        # valid_focal_loss_list.append(valid_focal_loss)\n",
    "    \n",
    "        # output training statistics for epoch\n",
    "        print('Epoch: {}'.format((e+1)))\n",
    "        print('\\t Training Loss: {:.6f} \\t Validation Loss: {:.6f}'\n",
    "                      .format(  train_loss, valid_loss))\n",
    "        # print('\\t Training Focal Loss: {:.6f} \\t Validation Focal Loss: {:.6f}'\n",
    "        #       .format( train_focal_loss, valid_focal_loss))\n",
    "    \n",
    "    plot_losses(train_loss_list, valid_loss_list, n_epoch, 'Loss')\n",
    "    # plot_losses(train_focal_loss_list, valid_focal_loss_list, n_epoch, 'Focal Loss')\n",
    "    # prepare model for evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    class_weights = class_weights.to('cpu')\n",
    "    preds_list = []\n",
    "    target_list = []\n",
    "    output_list = []\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    # test_focal_loss = 0.0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # number of classes\n",
    "    n_class = len(class_names)\n",
    "    \n",
    "    class_correct = np.zeros(n_class)\n",
    "    class_total = np.zeros(n_class)\n",
    "    \n",
    "    # move model back to cpu\n",
    "    model = model.to('cpu')\n",
    "    \n",
    "    # test model\n",
    "    for images, targets in test_loader:\n",
    "    \n",
    "        # get outputs\n",
    "        outputs = model(images)\n",
    "    \n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        # fl = get_focal_loss(loss)\n",
    "    \n",
    "        # track loss\n",
    "        test_loss += loss.item()\n",
    "        test_focal_loss += fl.item()\n",
    "        \n",
    "        # get predictions from probabilities\n",
    "        preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "    \n",
    "        target_list.extend(targets)\n",
    "        output_list.extend(torch.argmax(F.softmax(outputs, dim=1), dim=1 ))\n",
    "        preds_list.extend(preds)\n",
    "    \n",
    "        # get correct predictions\n",
    "        correct_preds = (preds == targets).type(torch.FloatTensor)\n",
    "    \n",
    "        # calculate and accumulate accuracy\n",
    "        accuracy += torch.mean(correct_preds).item() * 100\n",
    "    \n",
    "        # calculate test accuracy for each class\n",
    "        for c in range(n_class):\n",
    "    \n",
    "            targets = targets.to('cpu')\n",
    "    \n",
    "            class_total[c] += (targets == c).sum()\n",
    "            class_correct[c] += ((correct_preds) * (targets == c)).sum()\n",
    "    \n",
    "    # get average accuracy\n",
    "    accuracy = accuracy / len(test_loader)\n",
    "    \n",
    "    # get average loss\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    # test_focal_loss = test_focal_loss/ len(test_loader)\n",
    "    \n",
    "    # output test loss statistics\n",
    "    print('Test Loss: {:.6f}'.format(test_loss))\n",
    "    # print('Test Focal Loss: {:.6f}'.format(test_focal_loss))\n",
    "    \n",
    "    accuracy_per_class(class_correct, class_total, class_names, accuracy)\n",
    "    \n",
    "    get_metrics(preds_list, target_list)\n",
    "    today = date.today()\n",
    "    \n",
    "    final_pred_list = preds_list\n",
    "    final_target_list = target_list\n",
    "    \n",
    "    print(\"Saving ...\")\n",
    "    save_model(model, 'vit'+str(today())+'.pkl')\n",
    "    print(\"Finished ...\")\n",
    "    \n",
    "    return preds_list, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eaa79-d9dc-4dcd-ad95-8c1b13a34a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b9ab99e-92a7-4be4-b9a3-8d975aa8d1b9",
   "metadata": {},
   "source": [
    "### Model Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b615e9b-c315-4702-80de-80bb1e8015a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer\n",
    "lrs = [0.00001, 0.0001, 0.005, 0.001, 0.02 ,0.01, 0.1, 0.2, 0.5]\n",
    "epoches = [5, 10, 15, 25, 30, 50, 75, 100]\n",
    "\n",
    "lambda_norm = [ 0.025, 0.035, 0.045, 0.05, 0.075]\n",
    "lambda_wd = calculate_weight_decay(batch_size, len(train_loader_ws_all), epoches[2], lambda_norm[0])\n",
    "print(\"Lambda weight Decay\", lambda_wd)\n",
    "\n",
    "optimizer_0 = optim.Adam(filter(lambda p: p.requires_grad, vision_transformer.parameters()), lr=0.0001)\n",
    "optimizer_1 = optim.Adam(filter(lambda p: p.requires_grad, vision_transformer.parameters()), lr=0.001)\n",
    "optimizer_2 = optim.SGD(filter(lambda p: p.requires_grad, vision_transformer.parameters()), lr=0.0001)\n",
    "optimizer_3 = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=0.001,  weight_decay=0.1)\n",
    "optimizer_4 = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=0.0001,  weight_decay=0.1, amsgrad=True)\n",
    "optimizer_5 = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=0.0001,  weight_decay=0.1,betas= (0.9,0.999), amsgrad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6acc044-b2ac-4ed1-93b8-386d4c8c2d54",
   "metadata": {},
   "source": [
    "### Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76727859-2bcc-45be-9233-a6dc6052ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = setup_device()\n",
    "vision_transformer=get_vit_model()\n",
    "epoch = epoches[2]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=lrs[1],  weight_decay=0.1)\n",
    "train_on_gpu = torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5028d23-38de-480c-a65b-64a886444f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Epoches : \", epoch)\n",
    "print(\"Constant Weight Decay 0.1\")\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf1f50-24c8-4a60-ab6b-734db565c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_model(device, \n",
    "                 optimizer, \n",
    "                 criterion,\n",
    "                 train_on_gpu, \n",
    "                 class_weights_all, \n",
    "                 valid_loader_all, \n",
    "                 test_loader_all, \n",
    "                 vision_transformer, \n",
    "                 epoch, \n",
    "                 train_loader_ws_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdce83b-284b-4ad5-9300-ea55a96a8d14",
   "metadata": {},
   "source": [
    "#### Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf23df5-efdc-4447-a467-23e50466ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = setup_device()\n",
    "vision_transformer=get_vit_model()\n",
    "epoch = epoches[2]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=lrs[1],  weight_decay=lambda_wd)\n",
    "train_on_gpu = torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e51f2c-30c8-4d5b-af05-a333fb97f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Epoches : \", epoch)\n",
    "print(\"Weight Decay\", lambda_wd)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41ff33-6d2d-4585-86d7-9aa37daa51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_model(device, \n",
    "                 optimizer, \n",
    "                 criterion,\n",
    "                 train_on_gpu, \n",
    "                 class_weights_all, \n",
    "                 valid_loader_all, \n",
    "                 test_loader_all, \n",
    "                 vision_transformer, \n",
    "                 epoch, \n",
    "                 train_loader_ws_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f62762-2825-405a-a06a-35121f543461",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131bece-db04-44fd-aff4-d86095c3c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = setup_device()  ##'cuda' or 'cpu'\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 4   #CLASSES = 10 for cifar10 and 100 for cifar100\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 15\n",
    "LOG_INTERVAL = 15\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 504\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 173\n",
    "N_TEST_EXAMPLES = BATCHSIZE * 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42329f-6ba9-46ea-8875-c2462fe99f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    #lr = 0.001\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            val_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_VALID_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy #val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d9890-5e7e-40cc-a810-5e74dfd8bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "#study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "study.optimize(objective, n_trials=30, timeout=600)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15abbd51-dbe4-45db-9970-8d1817e178a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f71ad1-0543-46e3-b76d-eebc7fc4de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0be28b-f80a-431f-85e6-eb1c077debdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2f36d-9da8-45e3-b5f1-6b9206b8fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331dc00-a676-4c13-b90c-a94a444c9221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99041d51-d933-44c4-90d9-435a94f45e56",
   "metadata": {},
   "source": [
    "### Optuna Multiobjective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945bc2ab-9bc5-437d-abd6-f5d52f809be8",
   "metadata": {},
   "source": [
    "### Maximizing F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0c043e9-89b1-449d-b6a3-a750b0645c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    wd = trial.suggest_float(\"weight_decay\",0.01 ,2, log=True ) \n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd )\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            train_loss = 0.0\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        preds_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_TEST_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                target_list.extend(target)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                preds_list.extend(pred)\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TEST_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss = test_loss_batch / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        f1Score = get_F1Score(preds_list, target_list)\n",
    "        \n",
    "        trial.report(f1Score, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return f1Score #val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec9f1d9b-eaa0-4704-a610-38cdaf3d7487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 12:11:17,977] A new study created in memory with name: no-name-ece8a14f-ab22-4fdd-a1ff-5617b9dcdc8f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 14:40:00,999] Trial 0 finished with value: 0.5250606536865234 and parameters: {'optimizer': 'AdamW', 'lr': 0.0009608670155124675, 'weight_decay': 1.055065347024647}. Best is trial 0 with value: 0.5250606536865234.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "#study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "study.optimize(objective, n_trials=30, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "febad41a-a057-43a9-b6eb-14173cd662a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.5250606536865234\n",
      "  Params: \n",
      "    optimizer: AdamW\n",
      "    lr: 0.0009608670155124675\n",
      "    weight_decay: 1.055065347024647\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea6e09-7471-4165-adf4-2b772b2ce191",
   "metadata": {},
   "source": [
    "### SGD With momemtum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22ff7e39-5745-4bd0-8bc8-54630c06775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_f1(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"SGD\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    wd = trial.suggest_float(\"weight_decay\",0.01 ,2, log=True ) \n",
    "    montum = trial.suggest_float(\"momentum\", 0.5, 0.99, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd, momentum=montum )\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            train_loss = 0.0\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        preds_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_TEST_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                target_list.extend(target)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                preds_list.extend(pred)\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TEST_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss = test_loss_batch / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        f1Score = get_F1Score(preds_list, target_list)\n",
    "        \n",
    "        trial.report(f1Score, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return f1Score #val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4a49a48-4fbd-415c-a8bd-bf7cb2297548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 19:07:39,089] A new study created in memory with name: no-name-ffb46ab3-f0d7-4798-81c3-6ae67870a36a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 21:49:43,360] Trial 0 finished with value: 0.47744783759117126 and parameters: {'optimizer': 'SGD', 'lr': 0.004370372043736819, 'weight_decay': 0.01965512381896859, 'momentum': 0.8746091918588648}. Best is trial 0 with value: 0.47744783759117126.\n"
     ]
    }
   ],
   "source": [
    "study_sgd = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "#study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "study_sgd.optimize(objective_f1, n_trials=25, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0cf4c67-0fb1-4dc4-9181-bd99e89aed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.47744783759117126\n",
      "  Params: \n",
      "    optimizer: SGD\n",
      "    lr: 0.004370372043736819\n",
      "    weight_decay: 0.01965512381896859\n",
      "    momentum: 0.8746091918588648\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = [t for t in study_sgd.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study_sgd.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study_sgd.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study_sgd.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1213405-4d7a-4184-b813-f921bb5b39ea",
   "metadata": {},
   "source": [
    "### Maximizing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f7bea3c-9def-4e5d-846d-b5b17fe4766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_ACC(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    wd = trial.suggest_float(\"weight_decay\",0.01 ,2, log=True ) \n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd )\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            train_loss = 0.0\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        preds_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_TEST_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                target_list.extend(target)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                preds_list.extend(pred)\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TEST_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss = test_loss_batch / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        acc_from = get_Accuracy(preds_list, target_list)\n",
    "        \n",
    "        trial.report(acc_from, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return acc_from #val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6be65c45-ec01-4a4f-a479-6d9f34c1f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 14:40:01,013] A new study created in memory with name: no-name-2b97b55f-4495-470d-b44f-fd27610f1f59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 17:09:43,096] Trial 0 finished with value: 0.44950515031814575 and parameters: {'optimizer': 'AdamW', 'lr': 0.0004856281969016132, 'weight_decay': 1.644097743054941}. Best is trial 0 with value: 0.44950515031814575.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "#study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "study.optimize(objective_ACC, n_trials=30, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de74d8ef-c263-4458-b397-1597d843b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.44950515031814575\n",
      "  Params: \n",
      "    optimizer: AdamW\n",
      "    lr: 0.0004856281969016132\n",
      "    weight_decay: 1.644097743054941\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b7574-852c-4fa9-9ad1-6bc7d1096e77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Maximizing Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fc3b5c2-eb7e-4cf8-a155-79cf10cbec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectivePrecision(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    wd = trial.suggest_float(\"weight_decay\",0.01 ,2, log=True ) \n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd )\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            train_loss = 0.0\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        preds_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_TEST_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                target_list.extend(target)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                preds_list.extend(pred)\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TEST_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss = test_loss_batch / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        precision = get_Precision(preds_list, target_list)\n",
    "        \n",
    "        trial.report(precision, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return precision #val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb7ca1a6-202c-4879-b188-c97a26171090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 17:09:43,109] A new study created in memory with name: no-name-4aa8073a-75a5-460d-8d4c-3a994fa438e3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 19:47:42,063] Trial 0 finished with value: 0.5347465872764587 and parameters: {'optimizer': 'AdamW', 'lr': 0.06766327115344287, 'weight_decay': 0.27636857816992544}. Best is trial 0 with value: 0.5347465872764587.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "#study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "study.optimize(objectivePrecision, n_trials=30, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "865d26bd-1663-45a4-8878-d79f693d66d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.5347465872764587\n",
      "  Params: \n",
      "    optimizer: AdamW\n",
      "    lr: 0.06766327115344287\n",
      "    weight_decay: 0.27636857816992544\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200204ed-727f-40af-91c8-5672e33f178a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Maximizing Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d60b101-bcfe-4300-8d48-611eeb35fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRecall(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    wd = trial.suggest_float(\"weight_decay\",0.01 ,2, log=True ) \n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd )\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            train_loss = 0.0\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        preds_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_TEST_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                target_list.extend(target)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                preds_list.extend(pred)\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TEST_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss = test_loss_batch / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        recall = get_Recall(preds_list, target_list)\n",
    "        \n",
    "        trial.report(recall, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return recall #val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fabd2175-d4b6-4ce2-bf5c-7cde27b5634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 19:47:42,079] A new study created in memory with name: no-name-531ff6d0-523f-4c67-a5ff-cdf83f659095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-31 22:13:10,114] Trial 0 finished with value: 0.369500994682312 and parameters: {'optimizer': 'AdamW', 'lr': 0.008610244361088797, 'weight_decay': 0.03878816865309492}. Best is trial 0 with value: 0.369500994682312.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "#study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "study.optimize(objectiveRecall, n_trials=30, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05e80685-dbcb-4bb4-99e3-333148776523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.369500994682312\n",
      "  Params: \n",
      "    optimizer: AdamW\n",
      "    lr: 0.008610244361088797\n",
      "    weight_decay: 0.03878816865309492\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f98ecb-8a5f-4266-bf75-504066615485",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Minimizing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55c470-9271-4ea0-ac0f-3965226724b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = get_vit_model().to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    wd = trial.suggest_float(\"weight_decay\",0.01 ,2, log=True ) \n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd )\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "    \n",
    "    train_loss_list, valid_loss_list = [], []\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader, test_loader = train_loader_ws_all, valid_loader_all, test_loader_all\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            train_loss = 0.0\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        preds_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_TEST_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                target_list.extend(target)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                preds_list.extend(pred)\n",
    "                test_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        accuracy = correct / min(len(test_loader.dataset), N_TEST_EXAMPLES)\n",
    "        #val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        valid_loss = test_loss_batch / len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        recall = get_Recall(preds_list, target_list)\n",
    "        \n",
    "        trial.report(recall, epoch)\n",
    "        #trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return recall #val_loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d82459-3d93-4833-b0fd-aaa8e5126cda",
   "metadata": {},
   "source": [
    "### Saving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f3ca024-cc22-48a3-9a72-18fa69892085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda weight Decay 0.09707523451163974\n"
     ]
    }
   ],
   "source": [
    "# define optimizer\n",
    "lrs = 0.0009608670155124675\n",
    "epoches = 30\n",
    "\n",
    "lambda_norm = 1.055065347024647\n",
    "lambda_wd = calculate_weight_decay(batch_size, len(train_loader_ws_all), epoches, lambda_norm)\n",
    "print(\"Lambda weight Decay\", lambda_wd)\n",
    "\n",
    "optimizer_1 = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=0.0009608670155124675,  weight_decay=lambda_norm)\n",
    "optimizer_2 = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=0.0009608670155124675,  weight_decay=lambda_norm, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "80e4fb86-79bc-4334-877e-cfa68d7a18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  mps\n",
      "=============================== Model heads ==========================\n",
      "Sequential(\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "=============================== Model Layers ==========================\n",
      "Layer Name: class_token, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: conv_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.pos_embedding, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_0.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_1.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_2.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_3.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_4.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_5.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_6.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_7.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_8.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_9.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_10.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_1.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.in_proj_bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.self_attention.out_proj.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.ln_2.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.0.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.layers.encoder_layer_11.mlp.3.bias, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.weight, Frozen: True\n",
      "\n",
      "Layer Name: encoder.ln.bias, Frozen: True\n",
      "\n",
      "Layer Name: heads.weight, Frozen: False\n",
      "\n",
      "Layer Name: heads.bias, Frozen: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = setup_device()\n",
    "vision_transformer=get_vit_model()\n",
    "epoch = epoches\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, vision_transformer.parameters()),lr=0.0009608670155124675,  weight_decay=lambda_norm)\n",
    "train_on_gpu = torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74adb18-788d-4132-bdd4-a4f4aef31d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available :  mps\n",
      "Epoch: 1\n",
      "\t Training Loss: 1.077218 \t Validation Loss: 1.176775\n",
      "Epoch: 2\n",
      "\t Training Loss: 1.067132 \t Validation Loss: 1.118125\n",
      "Epoch: 3\n",
      "\t Training Loss: 1.067075 \t Validation Loss: 1.134796\n",
      "Epoch: 4\n",
      "\t Training Loss: 1.067304 \t Validation Loss: 1.108621\n",
      "Epoch: 5\n",
      "\t Training Loss: 1.069017 \t Validation Loss: 1.128782\n"
     ]
    }
   ],
   "source": [
    "test_preds, test_lbls = train_eval_model(device, \n",
    "                 optimizer, \n",
    "                 criterion,\n",
    "                 train_on_gpu, \n",
    "                 class_weights_all, \n",
    "                 valid_loader_all, \n",
    "                 test_loader_all,\n",
    "                 vision_transformer, \n",
    "                 epoch, \n",
    "                 train_loader_ws_all,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b9ed0-3615-49f3-9405-a1023475f411",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63706048-8768-4c6d-a13d-4fa1aeaf1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy, best_val_f1_score, best_val_precision, best_val_recall = None, None, None, None\n",
    "best_val_accuracy_trial, best_val_f1_score_trial, best_val_precision_trial, best_val_recall_trial = None, None, None, None\n",
    "\n",
    "\n",
    "for t, n in enumerate(study.trials):\n",
    "    print(f'trial: {t}, params: {n.params}, values: {n.values}')\n",
    "    \n",
    "    accuracy, f1_score, precision, recall = n.values[0], n.values[1], n.values[2], n.values[3]\n",
    "\n",
    "    if best_val_accuracy is None or accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = accuracy\n",
    "        best_val_accuracy_trial = t\n",
    "\n",
    "    if best_val_f1_score is None or f1_score < best_val_f1_score:\n",
    "        best_val_f1_score = f1_score\n",
    "        best_val_f1_score_trial = t\n",
    "\n",
    "    if best_val_precision is None or precision < best_val_f1_score:\n",
    "        best_val_precision = precision\n",
    "        best_val_precision_trial = t\n",
    "        \n",
    "    if best_val_recall is None or recall < best_val_recall_trial:\n",
    "        best_val_recall = recall\n",
    "        best_val_recall_trial = t\n",
    "\n",
    "print(f'\\nbest trial by accuracy: {best_val_accuracy_trial}')\n",
    "print(f'best trial by F1-score    : {best_val_f1_score_trial}\\n')\n",
    "print(f'best trial by precision    : {best_val_precision_trial}\\n')\n",
    "print(f'best trial by recall    : {best_val_recall_trial}\\n')\n",
    "\n",
    "# if best_val_accuracy_trial == best_val_loss_trial:\n",
    "#     print(f'best trial : {best_val_accuracy_trial}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794efb5c-81b2-42f6-ba5e-0a511d7b66fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b382d-b9bf-41c1-a626-7b243aa19134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbab5c4-cc18-482b-ac97-92dcf62b1cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alivio-tune",
   "language": "python",
   "name": "alivio-tune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
